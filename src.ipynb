{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "315f9753-ea13-4b4c-9190-53cfd1da9b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading training data...\n",
      "Train shape: (1639424, 7)\n",
      "2. Balancing dataset...\n",
      "3. Training model...\n",
      "[0]\tvalidation_0-logloss:0.29055\n",
      "[100]\tvalidation_0-logloss:0.08746\n",
      "[200]\tvalidation_0-logloss:0.07067\n",
      "[300]\tvalidation_0-logloss:0.06702\n",
      "[400]\tvalidation_0-logloss:0.06489\n",
      "[500]\tvalidation_0-logloss:0.06364\n",
      "[600]\tvalidation_0-logloss:0.06270\n",
      "[700]\tvalidation_0-logloss:0.06191\n",
      "[800]\tvalidation_0-logloss:0.06123\n",
      "[900]\tvalidation_0-logloss:0.06074\n",
      "[1000]\tvalidation_0-logloss:0.06038\n",
      "[1100]\tvalidation_0-logloss:0.06006\n",
      "[1200]\tvalidation_0-logloss:0.05983\n",
      "[1300]\tvalidation_0-logloss:0.05957\n",
      "[1400]\tvalidation_0-logloss:0.05936\n",
      "[1500]\tvalidation_0-logloss:0.05923\n",
      "[1600]\tvalidation_0-logloss:0.05910\n",
      "[1700]\tvalidation_0-logloss:0.05898\n",
      "[1800]\tvalidation_0-logloss:0.05891\n",
      "[1900]\tvalidation_0-logloss:0.05887\n",
      "[2000]\tvalidation_0-logloss:0.05889\n",
      "[2100]\tvalidation_0-logloss:0.05887\n",
      "[2200]\tvalidation_0-logloss:0.05886\n",
      "[2300]\tvalidation_0-logloss:0.05887\n",
      "[2400]\tvalidation_0-logloss:0.05889\n",
      "[2500]\tvalidation_0-logloss:0.05891\n",
      "[2600]\tvalidation_0-logloss:0.05897\n",
      "[2700]\tvalidation_0-logloss:0.05901\n",
      "[2800]\tvalidation_0-logloss:0.05905\n",
      "[2900]\tvalidation_0-logloss:0.05915\n",
      "[2999]\tvalidation_0-logloss:0.05925\n",
      "4. Optimizing threshold...\n",
      "========================================\n",
      "BEST F1: 0.8895\n",
      "BEST THRESHOLD: 0.422\n",
      "========================================\n",
      "5. Retraining on full dataset...\n",
      "6. Loading test data...\n",
      "Test shape: (409856, 7)\n",
      "7. Generating predictions...\n",
      "========================================\n",
      "SUCCESS: Submission saved as submission_file.csv\n",
      "========================================\n",
      "   ID  target\n",
      "0   0       0\n",
      "1   1       0\n",
      "2   2       0\n",
      "3   3       0\n",
      "4   4       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# =========================\n",
    "# SMART UNDERSAMPLING\n",
    "# =========================\n",
    "def smart_undersample(X, y, ratio=10):\n",
    "    df = X.copy()\n",
    "    df[\"target\"] = y\n",
    "\n",
    "    minority = df[df.target == 1]\n",
    "    majority = df[df.target == 0].sample(\n",
    "        n=len(minority) * ratio,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    balanced = pd.concat([minority, majority])\n",
    "    balanced = balanced.sample(frac=1, random_state=42)\n",
    "\n",
    "    return balanced.drop(columns=[\"target\"]), balanced[\"target\"]\n",
    "\n",
    "# =========================\n",
    "# MAIN PIPELINE\n",
    "# =========================\n",
    "def train_test_and_submit():\n",
    "\n",
    "    # =========================\n",
    "    # 1. LOAD TRAIN DATA\n",
    "    # =========================\n",
    "    print(\"1. Loading training data...\")\n",
    "    try:\n",
    "        df = pd.read_parquet(\"train.parquet\")\n",
    "    except:\n",
    "        df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    print(\"Train shape:\", df.shape)\n",
    "\n",
    "    if \"ID\" in df.columns:\n",
    "        df = df.drop(columns=[\"ID\"])\n",
    "\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    # =========================\n",
    "    # FEATURE HANDLING\n",
    "    # =========================\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == \"object\":\n",
    "            try:\n",
    "                X[col] = pd.to_datetime(X[col])\n",
    "            except:\n",
    "                X[col] = X[col].astype(\"category\")\n",
    "\n",
    "        if pd.api.types.is_datetime64_any_dtype(X[col]):\n",
    "            X[col] = X[col].astype(\"int64\") // 10**9\n",
    "\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    # =========================\n",
    "    # BALANCE DATA\n",
    "    # =========================\n",
    "    print(\"2. Balancing dataset...\")\n",
    "    X_bal, y_bal = smart_undersample(X, y, ratio=10)\n",
    "\n",
    "    # =========================\n",
    "    # SPLIT\n",
    "    # =========================\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_bal, y_bal,\n",
    "        test_size=0.2,\n",
    "        stratify=y_bal,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # MODEL\n",
    "    # =========================\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=8,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        gamma=0.05,\n",
    "        reg_alpha=0.5,\n",
    "        reg_lambda=1.5,\n",
    "        tree_method=\"hist\",\n",
    "        enable_categorical=True,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    print(\"3. Training model...\")\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)\n",
    "\n",
    "    # =========================\n",
    "    # THRESHOLD OPTIMIZATION\n",
    "    # =========================\n",
    "    print(\"4. Optimizing threshold...\")\n",
    "    probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0.5\n",
    "\n",
    "    for t in np.arange(0.1, 0.9, 0.002):\n",
    "        preds = (probs >= t).astype(int)\n",
    "        f1 = f1_score(y_val, preds)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = t\n",
    "\n",
    "    print(\"=\" * 40)\n",
    "    print(\"BEST F1:\", round(best_f1, 4))\n",
    "    print(\"BEST THRESHOLD:\", round(best_thresh, 3))\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # =========================\n",
    "    # RETRAIN ON FULL DATA\n",
    "    # =========================\n",
    "    print(\"5. Retraining on full dataset...\")\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # =========================\n",
    "    # 6. LOAD TEST DATA\n",
    "    # =========================\n",
    "    print(\"6. Loading test data...\")\n",
    "    try:\n",
    "        df_test = pd.read_parquet(\"test.parquet\")\n",
    "    except:\n",
    "        df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "    print(\"Test shape:\", df_test.shape)\n",
    "\n",
    "    if \"ID\" in df_test.columns:\n",
    "        test_ids = df_test[\"ID\"]\n",
    "        X_test = df_test.drop(columns=[\"ID\"])\n",
    "    else:\n",
    "        print(\"WARNING: No ID column found, using index\")\n",
    "        test_ids = df_test.index\n",
    "        X_test = df_test.copy()\n",
    "\n",
    "    # =========================\n",
    "    # PROCESS TEST FEATURES\n",
    "    # =========================\n",
    "    for col in X_test.columns:\n",
    "        if X_test[col].dtype == \"object\":\n",
    "            try:\n",
    "                X_test[col] = pd.to_datetime(X_test[col])\n",
    "            except:\n",
    "                X_test[col] = X_test[col].astype(\"category\")\n",
    "\n",
    "        if pd.api.types.is_datetime64_any_dtype(X_test[col]):\n",
    "            X_test[col] = X_test[col].astype(\"int64\") // 10**9\n",
    "\n",
    "    # =========================\n",
    "    # 7. PREDICT & SAVE CSV\n",
    "    # =========================\n",
    "    print(\"7. Generating predictions...\")\n",
    "    test_probs = model.predict_proba(X_test)[:, 1]\n",
    "    final_preds = (test_probs >= best_thresh).astype(int)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        \"ID\": test_ids,\n",
    "        \"target\": final_preds\n",
    "    })\n",
    "\n",
    "    output_file = \"submission_file.csv\"\n",
    "    submission.to_csv(output_file, index=False)\n",
    "\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"SUCCESS: Submission saved as {output_file}\")\n",
    "    print(\"=\" * 40)\n",
    "    print(submission.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_test_and_submit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706643a-98a9-4f85-9274-28c9f8fcecf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
